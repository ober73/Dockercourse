DOCKER COURSE

Multiple choice exams

2013
Docker used to use LXC

2014
but then docker introduced libcontainer


OCI

runtime-spec
image-spec

2016 things were broken down volumes images etc

and runC emerged to run containers

also containerd was introduced to manage the containers

then containerd-shim was created so that containers would continue to run even if the docker daemon stopped. It is detached. 

Docker manages 4 things

images, networks, containers, Volumes

INSTALL

docker system info  


docker daemon

dockerd --debug (for debugging)


when started it listens on rpc Unix Socket

/var/run/docker.sock (only can access on localhost)


we can open up the cli to outside by running the daemon like this

dockerd --debug \
        --hots=tcp://192.168.1.10:2375 (our host interface)
        
        
on the other host you can access docker by setting a variable

export DOCKER_HOST="tcp://192.168.1.10:2375"


you can enable encryption

dockerd --debug \
        --host=tcp://192.168.1.10:2376 \
        --tls=true
        --tlscert=/var/docker/server.pem \
        --tlskey=/var/docker/serverkey.pem
        
unencrypted 2375
encrypted 2376

you can move these settings to the docker daemon file

/etc/docker/daemon.json

{
  "debug": true,
  "hosts": ["tcp://192.168.1.10:2376"]
  "tls": true,
  "tlscert": "/var/docker/server.pem",
  "tlskey": "/var/docker/serverkey.pem"
}

docker container run -it ubuntu

docker image build .

docker container attach ubuntu

docker container kill ubuntu

docker container create httpd

container id has a short form as well


Stored in /var/lib/docker

containers in here

ls -lrt /var/lib/docker/containers/

ls -lrt /var/lib/docker/containers/36a391532e10*

Checkpoint hostconfig.json config.v2.json

docker container ls

docker container ls -a


docker container ls -l

docker container ls -q

docker container ls -aq

docker container start 36a391531e10

docker container run httpd

The ubuntu image runs then stops. What is the purpose of this?

To build other images on top of it.

docker container run -it ubuntu

i=interactive t=terminal

This will take us inside of the container

always add options before the container image name

to leave type exit


WE can add our own name

docker container run -itd --name=webapp ubuntu

To rename:
EX:
docker container rename webapp custom-webapp

By default container runs in attached mode


-d to detach mode


IF at some point later you want to re-attach to the container then run attach

EX:

docker container attach 11cb (use first digits of container id)

How to get ID's of running containers?

docker container ls -q


What flags are used to configure encryption on docker daemon

tlsverify, tlscert, tlskey
        
CTRL+p+q

puts container into detached mode

to run a command inside of the detached container
we can use exec

docker container exec b342fdsfwere <command>

or interactive again

docker contatiner exec -it b32432efasdfa /bin/bash

you can re-attach the container

docker container attach b71f1adswwerr


INSPECTING A CONTAINER

docker container inspect b7adfdasd


docker container stats (shows containers use of resources

or

docker container top <containername>


docker container logs 

docker system events --since 60m

LINUX SIGNALS

kill -SIGSTOP 13423

if you don't know the id you can replace with the pgrep command

kill -SIGSTOP $(pgrep htttpd)

SIGSTOP pauses the process 

to resume

kill -SIGCONT $(pgrep httpd)

to kill 

kill -SIGTERM polite way of asking process to stop

-SIGKILL is a force


each signal has a number as well

so

kill-9 


docker container pause

unpause

stop

docker uses freezer cgroup so that for certain containers will be paused or stops, i.e. they can't ignore like linux processes sometimes do.

You can kill processes inside the container by using the 

docker container kill --signal=9 web

REMOVE CONTAINER

stop container, then remove


docker container ls -q (lists only container id)

so you can add to commands

docker container stop $(docker container ls -q)

docker containter rm $(docker container ls -aq) use the a to show all containers even stopped ones

docker container prune (removes all stopped containers)

REMOVE FLAG

if we want the container to remove itself as soon as it has finihed its task

docker container run --rm ubuntu expr 4 + 5

docker container ls -l


/etc/lsb-release

docker container inspect

docker container top 52cweewrqer

docker container logs 25234324

docker container logs -f (shows realtime logs)

hostname is normally the beginning of the containerID

or set it

docker container run -it --name=webapp --hostname=webapp ubuntu

RESTART POLICY

if job completed then container will stop

docker container run ubuntu expr 3 + 5

Exited (0) code 0

or error (1) code 1

EX:

docker container run ubuntu expr three + 5

docker container run --restart= (this will auto restart

by default no

other settings on-failure, always, unless stopped

if you want your containers to continue working even if the docker daemon stops you can change the daemon properties

/etc/docker/daemon.json

{ 
  "debug": true,
  "host": ["tcp://192.168.1.10:2376"],
  "live-restore": true
}


COPYING FILES

docker container cp /tmp/web.conf webapp:/etc/web.conf 

SRC_PATH DEST_PATH

to copy container to host do opposite

PUBLISHING PORTS

docker run -p 80:5000 kodekloud/simple-webapp

all traffic on host at port 80 will get routed to port 5000 on the container


if you run the docker port mapping by default it is accesible on all the host interfaces

To limit that we specify the IP address with the port option:

docker run -p 192.168.1.5:8000:5000 kodekloud/simple-webapp

or you can do this

docker run -p 5000 kodekloud/simple-webapp 
this will publish to a random port on the host

it will be in the ephemeral port range => 32768 - 60999

cat /proc/sys/net/ipv4/ip_local_port_range
32768 60999


or run

docker run -P kodekloud/simple-webapp

Dockerfile

FROM ubuntu:16.04
RUN apt-get update && apt-get install -y python python-pip
RUN pip install flask
COPY app.py /opt/
ENTRYPOINT flask run
EXPOSE 5000

in the above case wi -P it will expose the pod on port 5000 in the dockerfile

you can expose additional ports on top of those in the dockerfile by using the --expose arg

docker run -P --expose=8000 kodekloud/simple-webapp

docker inspect kodekloud/simple-webapp

"ExposedPorts": {
   "5000/tcp": {},
   "8080/tcp": {}
},

docker relies on the kernel's IP Tables

DOCKER creates its own chain

DOCKER-USER DOCKER

iptables -t nat -S DOCKER


--rm (lookup why you would use this when creating a container)


docker system events --since 60m

docker container update --restart always httpd

DOCKER DAEMON TROUBLESHOOTING

docker host env variable

export DOCKER_HOST="tcp://192.168.1.10:2375"

2376 for encrypted traffic

journalctl -u docker.service

check config file

/etc/docker/daemon.json

df -h check space

docker container prune

docker image prune

docker system info

DEBUG MODE

turn on debug mode in the daemon.json file

{
  "debug": true
}


tail -50 /var/log/messages


you can also do

kill -SIGHUP 3664


LOGGING DRIVERS

docker logs nginx

all info for containers is stored under /var/lib/docker/containers

stored in json format

docker system info

shows where log plugins are

also you can manually set

docker run -d --log-driver json-file nginx

then check with docker container inspect nginx

IMAGE REGISTRY

dockerhub

on prem docker registry services

docker image ls


docker search httpd

--limit 2

--filter stars=10

is-official

docker image pull (only pulls down)

IMAGE ADDRESSING CONVENTION

image: httpd/httpd (first part is user account, second is image repository)

if not specified images pullsed from docker.io registry

so 

image: docker.io/httpd/httpd


AUTHENTICATING FROM REGISTRIES

for private registries or your own

docker login docker.io

docker login gcr.io

you can then push your images to a registry

docker image push httpd

create your own copy?

you can retag an image

docker image tag httpd:alpine httpd:customv1


docker system df (will show actual size)

REMOVE IMAGES

docker rm (but containers must be stopped)

docker image prune -a (delete all images not being used)


INSPECT IMAGE

docker image history ubuntu (will show all the commands to create the layers)


docker image inspect shows all info about image


output in json

you can use jsonpath

docker image inspect httpd -f '{{.Os}}'

-f '{{.Architecture}}' {{.Os}}'


IMAGE SAVE AND LOAD

for air gapped for example

docker image save alpine:latest -o alpine.tar

then in new location use the 

docker image load -i alpine.tar

You can also import and export containers

docker export <container-name> > testcontainter.tar

CREATE YOUR OWN IMAGE

1. OS Ubuntu

2. Update apt repo

3. Install dependencies using apt

4. Install Python dependencies using pip

5. Copy source code to /opt folder

6. Run the web server using "flask" command


Dockerfile

FROM Ubuntu

RUN apt-get update && apt-get -y install python

RUN pip install flask flask-mysql

COPY . /opt/source-code

ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run

docker build . -f Dockerfile -t mmumshad/my-custom-app

docker push mmumshad/my-custom-app

you can see the size of the layers if you run the docker history command followed by the image name

All the layers are cached so if one layer fails and you need to rerun another then it gets it from the cache

Dockerfile

FROM centos:7
RUN yum -y update
RUN yum -y install httpd
COPY ./index.html /var/www/html/index.html
EXPOSE 80
CMD ["httpd", "-D", "FORGEGROUND"]



you can also use ARG to set a variable

EX: ARG tomcat_version=8.5.6

Also to change the path in a container and make it the current working directory us

WORKDIR /

follow build command with a .

docker image build -t yogeshraheja/tomcatone:v1 .

after container built you can run the container like this

docker container run -itd --name=imagetesting -p 84:8080 yogeshraheja/tomcatone:v1

to use a different version we can run

docker image build -t yogeshraheja/tomcatone:v2 --build-arg tomcat_version=8.5.8 .


to customize a running container

docker container commit -a "Ravi" httpd customhttpd

not a reccomend approach, only one off or debug 

BUILD CONTEXT

. is the path

it boucl be /opt/ or anything

EX:

docker build /opt/my-custom-app

docker build .


all the files at this location are transferred to /var/lib/docker/tmp/docker-builderxxxxxx

only store the necessary files in the build context otherwise it increases the amount that is sent over.

you can use a .dockerignore file to ignore

you can also point to a url

docker build https://github/acd/myappp


docker build -f Dockerfile.dev https....


BUILD CACHE


if one layer is modified, i.e. a new package is added then all of the other layers are invalidated in the cache and need to be retrieved again

best practice combine apt-get update && apt-get isntall 

so that you get new packages

cache busting and version pinning

Optimize instruction to use cache

base not often changing stuff put first.

COPY VS ADD

ADD has more features

best practice

use COPY when you can

ADD is more differently so not as clear

add creates more layers which means bigger images

CMD vs ENTRYPOINT

CMD ["bash"]

you can append a command to the run command

docker run ubuntu sleep 5

you could create a new command and add it in the Dockerfile

FROM Ubuntu

CMD sleep 5

CMD command param1

CMD ["command", "param1"]

docker build -t ubuntu-sleeper .

you can use ENTRYPOINT in the Dockerfile and this will take parameters when run

FROM UBUNTU

ENTRYPOINT["sleep"]

docker run ubuntu-sleeper 10 (the 10 is added on to the sleep command)


If you want a default value for the command if the user does not provide an overide then put it in the dockefile

FROM Ubuntu

ENTRYPOINT ["sleep"]

CMD ["5"]

if you want to overide the command itself at startup then you can run the with entryppoint

EX:

docker run --entrypoint sleep2.0 ubuntu-sleeper 10


BASE vs PARENT IMAGE


when build from scratch it is the base image

there can be mulitple parent image

there is nothing inside a scratch image

EX:

debian:buster-slim (Dockerfile)

FROM scratch
ADD rootfs.tar.xz /
CMD ["bash"]

MULTISTAGE BUILDS

it is best to build your applications in Docker itself

EX:

Dockerfile.builder

FROM node
COPY ..
RUN npm install
RUN npm run build

docker build -t builder .

then Containerize it for production

EX:

Dockerfile

FROM nginx

COPY dist /usr/share/nginx/html

CMD ["nginx"], "-g", ["daemon off;"]

docker build -t my-app .

BUT 

we need a way to get the data into /usr/share/nginx/html where the Dockerfile is expecting it.


So Dockerfile.builder built an image but we only want the dist directory that was created in that image so that we can use it in the main Dockerfile

To get that we write a script:

copy-dist-from-builder.sh

docker container create --name builder builder
docker container cp builder:dist ./dist
docker container rm -f builder

Multi-stage builds allow us to combine these 3 stages into 1

EX:

Dockerfile

FROM node

COPY ..
RUN npm install
RUN npm run build

FROM nginx

COPY --from=0 dist /usr/share/nginx/html

CMD [ "nginx", "-g", "daemon off;" ]


so we have multiple FROM statements


or you can name the first stage like this

FROM node AS builder

below under the second FROM

COPY --from=builder


if you want to build a specific stage then you can do as follows:

docker build --target builder -t my-app .

BEST PRACTICES build

don't combine multiple applications in one container

build modular images

don't store data in containers

store on external volumes or in a caching service like Redis

keep images slim

only minimal

DOCKER SECURITY

Secure Docker Server

tls encryption 2376 port

add to docker/ daemon.json file

{ 
 "hosts": ["tcp://192.168.1.10:2376"]
 
 "tls": true,
 "tlscert": "/var/docker/server.pem",
 "tlskey": "/var/docker/serverkey.pem"
 "tlsverify": true,
 "tlscacert": "/var/docker/caserver.pem"
 }
 
 someone can now connect to this host from outside by setting the env variable
 
 export DOCKER_HOST="tcp://192.168.1.10:2376"
 
 export DOCKER_TLS=true
 
 on client side
 
 docker --tlscert=<> --tlskey=<> --tlscacert=<> ps
 
or drop the certs in the user ~/.docker folder where docker will automatically pick them up

NAMESPACES PID

processes on the host are run all in their own namespaces

you can set the user in the Docker image to non root

FROM Ubuntu

USER 1000

full list of linux capabilities can be found here
/usr/include/linux/capability.h

docker run --cap-add

or --cap-drop to remove capabilities

or for full privileges

docker run --privileged ubuntu

RESOURCE CONSUMPTION

by default no restrictions

sharing cpu on host

CFS Completely Fair Scheduler in linux

docker container run --cpu-shares=512 webapp4

you can limit certain containers to certain cpus

docker container run --cpuset-cpus=0-1 webapp1

now a newer option is to set counts

docker container run --cpus=2.5 webapp4

you can also use the docker container update --cpus=0.5 webapp4

MEMORY LINUX

docker container run --memory=512m webapp

if container tries to use more then it is killed

OOM (Out of Memory)

docker container run --memory=512 --memory-swap=512m webapp

DOCKER NETWORKING

when you install docker it creates 3 networks automatically

Bridge none host

to specify

docker run ubuntu (by default will be bridge)
docker run Ubuntu --network=none
docker run Ubuntu --network=host


Bridge is the internal docker network normally
ip 172.17.0.x

to access from the outside you need to map to the outside


for host network it is directly connected to the outside

you can only use one port when using host per app

so 5000 used once means it is unavailable


You can create another network as well

docker network create \
  --driver bridge \
  --subnet 182.18.0.0/16
  custom-isolated-network
  
  
  docker network ls
  
Embedded DNS

docker has a buildin DNS server

the builtin dns server runs at 127.0.0.11

docker uses docker namespaces

docker network connect custom-net my-container


docker network disconnect custom-net my-container

docker network rm custom-net

docker network prune

EMBEDDED DNS won't work with the default bridge network


create a new network 

EX:

docker network create --driver=bridge --subnet=192.168.10.0/24 kodekloudnet

docker network ls

docker network inspect kodekloudnet

Then create a container

EX:
docker container run -itd --name=customfirst --net=kodekloudnet centos: 7

Userdefined networks have embedded DNS enabled


TO Connect a container to a network use
EX:
docker network connect kodekloudnet first

you can also use 

docker network disconnect 


you can't remove a network if you have containers attached to it.

to stop all containers

docker container stop $(docker container ls -q)

docker container rm $(docker container ls -aq)



LINUX NAMESPACES

process runs inside the container with one pid

but in the host with a different pid


To create new network namespaces run the

ip netns add red

ip netns add blue

to list the namespaces run the ip netns command

ip link

to see the same information in a namespace run the ip netns exec red ip link

or run with -n

ip -n red link

if you run arp on the host you see entries

but not when you run inside ns

ip netns exec red arp

TO CONNECT TWO NAMESPACES RUN:

ip link add veth-red type veth peer name veth-blue

then set to the appropriate ns

ip link set veth-red netns red

then assign IPs

ip -n red addr add 192.168.15.1 dev veth-red

ip -n red link set veth-red up

IF YOU HAVE MULTIPLE NETWORKS THEN YOU NEED TO CREATE A BRIDGE

a few solutions but most popular

LINUX BRIDGE OvS
Open vSwtich

ip link add v-net-0 type bridge

ip link set dev v-net-0 up

THen you can delete the original links, only need to delete one side

ip -n red link del veth-red

NOW CONNECT TO THE SWITCH

ip link add veth-red type veth peer name veth-red-br

ip link set veth-red netns red

ip link set veth-red-br master v-net-0

Connect bridge to host

ip addr add 192.168.15.5/24 dev v-net-0

add route so blue can get to outside

ip netns exec blue ip route add 192.168.1.0/24 via 192.168.15.5

for communication we need to add NAT we do this with IPTABLES

iptables -t nat -A POSTROUTING -s 192.168.15.0/24 -j MASQUERADE

For access from the outside inside we use portforwarding

iptables -t nat -A PREROUTING --dport 80 --to-destination 192.168.15.2:80 -j DNAT

DOCKER NETWORKING

none

host

bridge


docker run nginx (default bridge)


docker creates a network

docker network ls

bridge

on the host it is docker0

ip link command will show that

ip netns

Interfaces on the bridge are odd

on the containers the they are even

EX:

container eth0@if12----------------bridge@if11

docker run -p 8080:80 nginx

to see the rules that docker creates use:

iptables -nvL -t nat


STORAGE

Storage drivers and volume drivers


docker volume inspect data_volume

docker container run --mount \
source=data_vol1,destination=/var/www/html/index.html,readonly httpd

docker volume ls

T
docker volume create testvol

docker container run -itd --name=test -v testvol:/yogesh centos:7

BY default volumes are created in rw mode

but you can mount read-only if you want


docker container stop $(docker container ls -q)

docker container rm $(docker container ls -aq)

docker volume prune


TO MOUNT on the host use bind

docker container run -itd --mount type=bind,source=/data,destination=/yogesh conetos:7

In the bind method we won't be able to see a list of volumes

DOCKER COMPOSE

voter application 

We use docker run --links to tell different contatiners to work with each other.

docker run -d --name=vote -p 5000:80 --link redis:redis voting-app

this creates a line in the /etc/hosts file to the redis container with its IP

LINKS IS DEPRECATED

create a dictionary of images and names


EX:

redis:
  image: redis
  
db:
  image: postgres:9.4
  
  
  
docker compose up



EX:

links:
  - db
  - redis
  
  
You can also use build and point to a folder

vote:
  build: ./vote
  
  
Docker compose - versions


there are different versions and compose has expanded its supported thigns

format of the file changed as well


version 1 and version 2



at top for 

version: 2

version 2 creates and overlay network, no need to use links


it also adds depends_on:


version: 3 now

3 has docker swarm support

INSTALL DOCKER COMPOSE

install using script from web site

you can stop multiple containers using first two letters

docker stop 69 53 25 53

CREATE a docker compose file

cat > docker-compose.yml

redis: 
  image: redis

db:
  image: postgres:9.4

vote:
  image: voting-app
  ports:
    - 5000:80
worker:
  image: worker-app
  links:
  - db
  - redis
result:
  image: result-app
  ports:
  - 5001:80
  links:
    - db
    

THEN run docker-compose up 


whatever folder you are in it prefixes that to the container name

THAT WAS THE OLDER VERSION OF DOCKER

we will now upgrade our version

new vesrsion of the file


version: "3"

services:
  
  redis: 
  image: redis

  db:
    image: postgres:9.4
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres

  vote:
    image: voting-app
    ports:
      - 5000:80
  worker:
    image: worker-app
    
  result:
    image: result-app
    ports:
    - 5001:80
    


This will automatically create a network and connect all of these containers and we no longer need the links section






List containers created by compose file

docker-compose ps

docker-compose down


DOCKER SWARM

Manager node and worker nodes

docker-compose files are used


docker system info

...

Swarm: inactive or active

docker swarm init

docker swarm join --token

docker node ls

if you lose the token you can regenerate again

docker node inspect





 
 
 

























