DOCKER COURSE

Multiple choice exams

2013
Docker used to use LXC

2014
but then docker introduced libcontainer


OCI

runtime-spec
image-spec

2016 things were broken down volumes images etc

and runC emerged to run containers

also containerd was introduced to manage the containers

then containerd-shim was created so that containers would continue to run even if the docker daemon stopped. It is detached. 

Docker manages 4 things

images, networks, containers, Volumes

INSTALL

docker system info  


docker daemon

dockerd --debug (for debugging)


when started it listens on rpc Unix Socket

/var/run/docker.sock (only can access on localhost)


we can open up the cli to outside by running the daemon like this

dockerd --debug \
        --hots=tcp://192.168.1.10:2375 (our host interface)
        
        
on the other host you can access docker by setting a variable

export DOCKER_HOST="tcp://192.168.1.10:2375"


you can enable encryption

dockerd --debug \
        --host=tcp://192.168.1.10:2376 \
        --tls=true
        --tlscert=/var/docker/server.pem \
        --tlskey=/var/docker/serverkey.pem
        
unencrypted 2375
encrypted 2376

you can move these settings to the docker daemon file

/etc/docker/daemon.json

{
  "debug": true,
  "hosts": ["tcp://192.168.1.10:2376"]
  "tls": true,
  "tlscert": "/var/docker/server.pem",
  "tlskey": "/var/docker/serverkey.pem"
}

docker container run -it ubuntu

docker image build .

docker container attach ubuntu

docker container kill ubuntu

docker container create httpd

container id has a short form as well


Stored in /var/lib/docker

containers in here

ls -lrt /var/lib/docker/containers/

ls -lrt /var/lib/docker/containers/36a391532e10*

Checkpoint hostconfig.json config.v2.json

docker container ls

docker container ls -a


docker container ls -l

docker container ls -q

docker container ls -aq

docker container start 36a391531e10

docker container run httpd

The ubuntu image runs then stops. What is the purpose of this?

To build other images on top of it.

docker container run -it ubuntu

i=interactive t=terminal

This will take us inside of the container

always add options before the container image name

to leave type exit


WE can add our own name

docker container run -itd --name=webapp ubuntu

To rename:
EX:
docker container rename webapp custom-webapp

By default container runs in attached mode


-d to detach mode


IF at some point later you want to re-attach to the container then run attach

EX:

docker container attach 11cb (use first digits of container id)

How to get ID's of running containers?

docker container ls -q


What flags are used to configure encryption on docker daemon

tlsverify, tlscert, tlskey
        
CTRL+p+q

puts container into detached mode

to run a command inside of the detached container
we can use exec

docker container exec b342fdsfwere <command>

or interactive again

docker contatiner exec -it b32432efasdfa /bin/bash

you can re-attach the container

docker container attach b71f1adswwerr


INSPECTING A CONTAINER

docker container inspect b7adfdasd


docker container stats (shows containers use of resources

or

docker container top <containername>


docker container logs 

docker system events --since 60m

LINUX SIGNALS

kill -SIGSTOP 13423

if you don't know the id you can replace with the pgrep command

kill -SIGSTOP $(pgrep htttpd)

SIGSTOP pauses the process 

to resume

kill -SIGCONT $(pgrep httpd)

to kill 

kill -SIGTERM polite way of asking process to stop

-SIGKILL is a force


each signal has a number as well

so

kill-9 


docker container pause

unpause

stop

docker uses freezer cgroup so that for certain containers will be paused or stops, i.e. they can't ignore like linux processes sometimes do.

You can kill processes inside the container by using the 

docker container kill --signal=9 web

REMOVE CONTAINER

stop container, then remove


docker container ls -q (lists only container id)

so you can add to commands

docker container stop $(docker container ls -q)

docker containter rm $(docker container ls -aq) use the a to show all containers even stopped ones

docker container prune (removes all stopped containers)

REMOVE FLAG

if we want the container to remove itself as soon as it has finihed its task

docker container run --rm ubuntu expr 4 + 5

docker container ls -l


/etc/lsb-release

docker container inspect

docker container top 52cweewrqer

docker container logs 25234324

docker container logs -f (shows realtime logs)

hostname is normally the beginning of the containerID

or set it

docker container run -it --name=webapp --hostname=webapp ubuntu

RESTART POLICY

if job completed then container will stop

docker container run ubuntu expr 3 + 5

Exited (0) code 0

or error (1) code 1

EX:

docker container run ubuntu expr three + 5

docker container run --restart= (this will auto restart

by default no

other settings on-failure, always, unless stopped

if you want your containers to continue working even if the docker daemon stops you can change the daemon properties

/etc/docker/daemon.json

{ 
  "debug": true,
  "host": ["tcp://192.168.1.10:2376"],
  "live-restore": true
}


COPYING FILES

docker container cp /tmp/web.conf webapp:/etc/web.conf 

SRC_PATH DEST_PATH

to copy container to host do opposite

PUBLISHING PORTS

docker run -p 80:5000 kodekloud/simple-webapp

all traffic on host at port 80 will get routed to port 5000 on the container


if you run the docker port mapping by default it is accesible on all the host interfaces

To limit that we specify the IP address with the port option:

docker run -p 192.168.1.5:8000:5000 kodekloud/simple-webapp

or you can do this

docker run -p 5000 kodekloud/simple-webapp 
this will publish to a random port on the host

it will be in the ephemeral port range => 32768 - 60999

cat /proc/sys/net/ipv4/ip_local_port_range
32768 60999


or run

docker run -P kodekloud/simple-webapp

Dockerfile

FROM ubuntu:16.04
RUN apt-get update && apt-get install -y python python-pip
RUN pip install flask
COPY app.py /opt/
ENTRYPOINT flask run
EXPOSE 5000

in the above case wi -P it will expose the pod on port 5000 in the dockerfile

you can expose additional ports on top of those in the dockerfile by using the --expose arg

docker run -P --expose=8000 kodekloud/simple-webapp

docker inspect kodekloud/simple-webapp

"ExposedPorts": {
   "5000/tcp": {},
   "8080/tcp": {}
},

docker relies on the kernel's IP Tables

DOCKER creates its own chain

DOCKER-USER DOCKER

iptables -t nat -S DOCKER


--rm (lookup why you would use this when creating a container)


docker system events --since 60m

docker container update --restart always httpd

DOCKER DAEMON TROUBLESHOOTING

docker host env variable

export DOCKER_HOST="tcp://192.168.1.10:2375"

2376 for encrypted traffic

journalctl -u docker.service

check config file

/etc/docker/daemon.json

df -h check space

docker container prune

docker image prune

docker system info

DEBUG MODE

turn on debug mode in the daemon.json file

{
  "debug": true
}


tail -50 /var/log/messages


you can also do

kill -SIGHUP 3664


LOGGING DRIVERS

docker logs nginx

all info for containers is stored under /var/lib/docker/containers

stored in json format

docker system info

shows where log plugins are

also you can manually set

docker run -d --log-driver json-file nginx

then check with docker container inspect nginx

IMAGE REGISTRY

dockerhub

on prem docker registry services

docker image ls


docker search httpd

--limit 2

--filter stars=10

is-official

docker image pull (only pulls down)

IMAGE ADDRESSING CONVENTION

image: httpd/httpd (first part is user account, second is image repository)

if not specified images pullsed from docker.io registry

so 

image: docker.io/httpd/httpd


AUTHENTICATING FROM REGISTRIES

for private registries or your own

docker login docker.io

docker login gcr.io

you can then push your images to a registry

docker image push httpd

create your own copy?

you can retag an image

docker image tag httpd:alpine httpd:customv1


docker system df (will show actual size)

REMOVE IMAGES

docker rm (but containers must be stopped)

docker image prune -a (delete all images not being used)


INSPECT IMAGE

docker image history ubuntu (will show all the commands to create the layers)


docker image inspect shows all info about image


output in json

you can use jsonpath

docker image inspect httpd -f '{{.Os}}'

-f '{{.Architecture}}' {{.Os}}'


IMAGE SAVE AND LOAD

for air gapped for example

docker image save alpine:latest -o alpine.tar

then in new location use the 

docker image load -i alpine.tar

You can also import and export containers

docker export <container-name> > testcontainter.tar

CREATE YOUR OWN IMAGE

1. OS Ubuntu

2. Update apt repo

3. Install dependencies using apt

4. Install Python dependencies using pip

5. Copy source code to /opt folder

6. Run the web server using "flask" command


Dockerfile

FROM Ubuntu

RUN apt-get update && apt-get -y install python

RUN pip install flask flask-mysql

COPY . /opt/source-code

ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run

docker build . -f Dockerfile -t mmumshad/my-custom-app

docker push mmumshad/my-custom-app

you can see the size of the layers if you run the docker history command followed by the image name

All the layers are cached so if one layer fails and you need to rerun another then it gets it from the cache

Dockerfile

FROM centos:7
RUN yum -y update
RUN yum -y install httpd
COPY ./index.html /var/www/html/index.html
EXPOSE 80
CMD ["httpd", "-D", "FORGEGROUND"]



you can also use ARG to set a variable

EX: ARG tomcat_version=8.5.6

Also to change the path in a container and make it the current working directory us

WORKDIR /

follow build command with a .

docker image build -t yogeshraheja/tomcatone:v1 .

after container built you can run the container like this

docker container run -itd --name=imagetesting -p 84:8080 yogeshraheja/tomcatone:v1

to use a different version we can run

docker image build -t yogeshraheja/tomcatone:v2 --build-arg tomcat_version=8.5.8 .


to customize a running container

docker container commit -a "Ravi" httpd customhttpd

not a reccomend approach, only one off or debug 

BUILD CONTEXT

. is the path

it boucl be /opt/ or anything

EX:

docker build /opt/my-custom-app

docker build .


all the files at this location are transferred to /var/lib/docker/tmp/docker-builderxxxxxx

only store the necessary files in the build context otherwise it increases the amount that is sent over.

you can use a .dockerignore file to ignore

you can also point to a url

docker build https://github/acd/myappp


docker build -f Dockerfile.dev https....


BUILD CACHE


if one layer is modified, i.e. a new package is added then all of the other layers are invalidated in the cache and need to be retrieved again

best practice combine apt-get update && apt-get isntall 

so that you get new packages

cache busting and version pinning

Optimize instruction to use cache

base not often changing stuff put first.

COPY VS ADD

ADD has more features

best practice

use COPY when you can

ADD is more differently so not as clear

add creates more layers which means bigger images

CMD vs ENTRYPOINT

CMD ["bash"]

you can append a command to the run command

docker run ubuntu sleep 5

you could create a new command and add it in the Dockerfile

FROM Ubuntu

CMD sleep 5

CMD command param1

CMD ["command", "param1"]

docker build -t ubuntu-sleeper .

you can use ENTRYPOINT in the Dockerfile and this will take parameters when run

FROM UBUNTU

ENTRYPOINT["sleep"]

docker run ubuntu-sleeper 10 (the 10 is added on to the sleep command)


If you want a default value for the command if the user does not provide an overide then put it in the dockefile

FROM Ubuntu

ENTRYPOINT ["sleep"]

CMD ["5"]

if you want to overide the command itself at startup then you can run the with entryppoint

EX:

docker run --entrypoint sleep2.0 ubuntu-sleeper 10


BASE vs PARENT IMAGE


when build from scratch it is the base image

there can be mulitple parent image

there is nothing inside a scratch image

EX:

debian:buster-slim (Dockerfile)

FROM scratch
ADD rootfs.tar.xz /
CMD ["bash"]

MULTISTAGE BUILDS

it is best to build your applications in Docker itself

EX:

Dockerfile.builder

FROM node
COPY ..
RUN npm install
RUN npm run build

docker build -t builder .

then Containerize it for production

EX:

Dockerfile

FROM nginx

COPY dist /usr/share/nginx/html

CMD ["nginx"], "-g", ["daemon off;"]

docker build -t my-app .

BUT 

we need a way to get the data into /usr/share/nginx/html where the Dockerfile is expecting it.


So Dockerfile.builder built an image but we only want the dist directory that was created in that image so that we can use it in the main Dockerfile

To get that we write a script:

copy-dist-from-builder.sh

docker container create --name builder builder
docker container cp builder:dist ./dist
docker container rm -f builder

Multi-stage builds allow us to combine these 3 stages into 1

EX:

Dockerfile

FROM node

COPY ..
RUN npm install
RUN npm run build

FROM nginx

COPY --from=0 dist /usr/share/nginx/html

CMD [ "nginx", "-g", "daemon off;" ]


so we have multiple FROM statements


or you can name the first stage like this

FROM node AS builder

below under the second FROM

COPY --from=builder


if you want to build a specific stage then you can do as follows:

docker build --target builder -t my-app .

BEST PRACTICES build

don't combine multiple applications in one container

build modular images

don't store data in containers

store on external volumes or in a caching service like Redis

keep images slim

only minimal

DOCKER SECURITY

Secure Docker Server

tls encryption 2376 port

add to docker/ daemon.json file

{ 
 "hosts": ["tcp://192.168.1.10:2376"]
 
 "tls": true,
 "tlscert": "/var/docker/server.pem",
 "tlskey": "/var/docker/serverkey.pem"
 "tlsverify": true,
 "tlscacert": "/var/docker/caserver.pem"
 }
 
 someone can now connect to this host from outside by setting the env variable
 
 export DOCKER_HOST="tcp://192.168.1.10:2376"
 
 export DOCKER_TLS=true
 
 on client side
 
 docker --tlscert=<> --tlskey=<> --tlscacert=<> ps
 
or drop the certs in the user ~/.docker folder where docker will automatically pick them up

NAMESPACES PID

processes on the host are run all in their own namespaces

you can set the user in the Docker image to non root

FROM Ubuntu

USER 1000

full list of linux capabilities can be found here
/usr/include/linux/capability.h

docker run --cap-add

or --cap-drop to remove capabilities

or for full privileges

docker run --privileged ubuntu

RESOURCE CONSUMPTION

by default no restrictions

sharing cpu on host

CFS Completely Fair Scheduler in linux

docker container run --cpu-shares=512 webapp4

you can limit certain containers to certain cpus

docker container run --cpuset-cpus=0-1 webapp1

now a newer option is to set counts

docker container run --cpus=2.5 webapp4

you can also use the docker container update --cpus=0.5 webapp4

MEMORY LINUX

docker container run --memory=512m webapp

if container tries to use more then it is killed

OOM (Out of Memory)

docker container run --memory=512 --memory-swap=512m webapp


 
 
 

























